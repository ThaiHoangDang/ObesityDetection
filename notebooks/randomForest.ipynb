{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangdang/miniconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "1440 fits failed out of a total of 2880.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "862 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "578 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/hoangdang/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87294977 0.87260723 0.87421323 0.87329485 0.8735744  0.87330577\n",
      " 0.87349894 0.87322659 0.87346072 0.87376163 0.87350663 0.87375057\n",
      " 0.87397362 0.87361449 0.87306667 0.87367221 0.87399822 0.87374777\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.86809384 0.86819072 0.86855084 0.86870537 0.8682476  0.86831594\n",
      " 0.86811725 0.86833968 0.86826311 0.86832147 0.86825201 0.86825046\n",
      " 0.86817759 0.86837208 0.86841618 0.86788195 0.86814646 0.86795206\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87368903 0.87333623 0.87394258 0.87388941 0.87335159 0.87337595\n",
      " 0.87395125 0.87389773 0.87357759 0.8735332  0.87353336 0.8734873\n",
      " 0.87403649 0.87379655 0.8738018  0.87365754 0.87344487 0.87368752\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87331568 0.87247237 0.87350141 0.87316374 0.87372982 0.87334019\n",
      " 0.87367571 0.87362396 0.87343825 0.87359113 0.87390315 0.87370997\n",
      " 0.87369457 0.87374303 0.87375879 0.87331366 0.87335065 0.8737807\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87398611 0.87385672 0.87429526 0.8743148  0.86995334 0.87002089\n",
      " 0.87260632 0.87353182 0.87273728 0.87227078 0.86903596 0.86951468\n",
      " 0.86688235 0.86700663 0.86650814 0.86683363 0.86628045 0.86572542\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84666851 0.8464344  0.84691615 0.84641461 0.84585644 0.84650365\n",
      " 0.84691101 0.84660963 0.84638897 0.8460708  0.84664127 0.84623216\n",
      " 0.84604054 0.84628096 0.84623044 0.84610445 0.84608181 0.84597681\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87459458 0.8738121  0.87176553 0.87264577 0.8694451  0.86955035\n",
      " 0.87117476 0.87218052 0.87119533 0.87105126 0.86821116 0.86830646\n",
      " 0.8663774  0.8660698  0.86615367 0.86611801 0.8654209  0.86513063\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87419616 0.87419112 0.87425454 0.87475185 0.87010891 0.86999914\n",
      " 0.87274702 0.87308501 0.87221776 0.87272704 0.86865504 0.86931245\n",
      " 0.86703974 0.86684319 0.86709713 0.86697916 0.86605867 0.86575725]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__class_weight': 'balanced', 'classifier__max_depth': 30, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 400}\n",
      "F1 Score: 0.8696885968187589\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "health_data = pd.read_csv(\"../data/data_train.csv\", delimiter=\",\", index_col=\"Id\")\n",
    "health_data = health_data.drop_duplicates()\n",
    "selected_features = ['HighBP', 'HighChol', 'BMI',\n",
    "       'HeartDiseaseorAttack', 'PhysActivity', 'GenHlth', \n",
    "       'PhysHlth', 'DiffWalk', 'Age', 'Education', 'Income',\n",
    "       'ExtraMedTest', 'ExtraAlcoholTest']\n",
    "X = health_data[selected_features].copy()\n",
    "y = health_data.Status\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Define the pipeline with polynomial feature expansion\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [300, 400],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['auto', 'sqrt'],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=kf, n_jobs=-1, scoring='f1')\n",
    "\n",
    "# Train the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_valid)\n",
    "f1 = f1_score(y_valid, y_pred)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
